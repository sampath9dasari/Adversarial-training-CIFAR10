{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtGWRtigJF2z"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow_hub as thub\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from lib.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtGWRtigJF2z"
   },
   "outputs": [],
   "source": [
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks.extraction import CopycatCNN, FunctionallyEquivalentExtraction, KnockoffNets\n",
    "import art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_by_class(data, labels, num_samples=100):\n",
    "    sample_data = []\n",
    "    sample_labels = []\n",
    "    unq_labels = list(range(labels.shape[1]))\n",
    "    for label in unq_labels:\n",
    "        idx = labels[:,label]==1\n",
    "        sample_set = data[idx][0:num_samples].copy()\n",
    "        label_set = labels[idx][0:num_samples].copy()\n",
    "        sample_data.append(sample_set)\n",
    "        sample_labels.append(label_set)\n",
    "    \n",
    "    sample_data = np.concatenate(sample_data)\n",
    "    sample_labels = np.concatenate(sample_labels)\n",
    "    print(sample_data.shape, sample_labels.shape)\n",
    "    return sample_data, sample_labels\n",
    "\n",
    "def subset_data(data, labels, fraction=5):\n",
    "    data_size = data.shape[0]\n",
    "    out_size = int(data_size*fraction/100)\n",
    "    idx = np.random.choice(data_size, out_size, replace=False)\n",
    "    out_data = data[idx].copy()\n",
    "    out_labels = labels[idx].copy()\n",
    "    \n",
    "    print(out_data.shape, out_labels.shape)\n",
    "    return out_data, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpom9Hy7JPVV"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "# from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJ9lwH3jbohO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data\n",
    "cifar10_dir = 'lib/datasets/cifar-10-batches-py'\n",
    "x_train, y_train, x_test, y_test = load_cifar10(cifar10_dir)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkN3V0v_cZBj"
   },
   "outputs": [],
   "source": [
    "testd = x_train[0:1000].copy()\n",
    "testl = y_train[0:1000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ganeval_model(enable_logits=True):\n",
    "    K.clear_session()\n",
    "    model_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n",
    "    ganeval_module = thub.Module(model_url)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(32,32,3)))\n",
    "    model.add(thub.KerasLayer(ganeval_module))\n",
    "    if enable_logits:\n",
    "        model.add(tf.keras.layers.Activation('linear'))\n",
    "    else: \n",
    "        model.add(tf.keras.layers.Activation('softmax'))\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=1e-4),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 10)                7796426   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,796,426\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,796,426\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ge_cifar_clf = build_ganeval_model(enable_logits=True)\n",
    "ge_cifar_clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing the retrieved hub model by evaluating on train data\n",
    "Should give us 100% or something close to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 0.0017 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001668029203079641, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_cifar_clf.evaluate(testd, testl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing a sample attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNmpFslsKbfD"
   },
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "attack_fgsm = FastGradientMethod(classifier=classifier, eps=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1nIaChockte"
   },
   "outputs": [],
   "source": [
    "x_test_adv = attack_fgsm.generate(testd.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dH4KvoVocrqf",
    "outputId": "dd3f1325-b761-428f-ad6b-f55b1b265e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 6.9334 - acc: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.933382461547851, 0.102]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_cifar_clf.evaluate(x_test_adv, testl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the substitute classifier for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_substitute_model(enable_logits=True):\n",
    "    model = tf.keras.Sequential( )\n",
    "    model.add( Conv2D( 32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32,32,3) ) )\n",
    "    model.add( Conv2D( 64, (3, 3), padding='same', activation='relu' ) )\n",
    "    model.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
    "    model.add( Flatten( ) )\n",
    "    model.add( Dense( 128, activation='relu' ) )\n",
    "    if enable_logits:\n",
    "        model.add( Dense(10, activation='linear' ) )\n",
    "    else:\n",
    "        model.add( Dense(10, activation='softmax' ) )\n",
    "        \n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'] )\n",
    "    \n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_substitute_model(enable_logits=True):\n",
    "    model = tf.keras.Sequential( )\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32,32,3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    if enable_logits:\n",
    "        model.add(Activation(\"linear\"))\n",
    "    else:\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'] )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3) (1000, 10)\n",
      "(1000, 32, 32, 3) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_data_fraction = [5,10,20,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 32, 32, 3) (15000, 10)\n"
     ]
    }
   ],
   "source": [
    "partial_x_train, partial_y_train = subset_data(x_train, y_train, fraction=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "ge_cifar_clf = build_ganeval_model()\n",
    "sub_clf1 = build_substitute_model()\n",
    "sub_clf2 = build_substitute_model()\n",
    "# sub_clf1.summary()\n",
    "# sub_clf2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cloud_art_clf = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "stolen_clf1 = KerasClassifier(model=sub_clf1, clip_values=(0, 1), use_logits=True)\n",
    "stolen_clf2 = KerasClassifier(model=sub_clf2, clip_values=(0, 1), use_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attack_CCC = CopycatCNN(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=20,\n",
    "                        nb_stolen=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "312/312 [==============================] - 21s 69ms/step - loss: 1.9312 - acc: 0.2827\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 21s 66ms/step - loss: 1.5368 - acc: 0.4444\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 21s 68ms/step - loss: 1.3660 - acc: 0.5044\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 21s 68ms/step - loss: 1.2385 - acc: 0.5556\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 21s 68ms/step - loss: 1.1089 - acc: 0.6033\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.0365 - acc: 0.6374\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.9561 - acc: 0.6597\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.8998 - acc: 0.6789\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.8079 - acc: 0.7151\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.7722 - acc: 0.7303\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.7037 - acc: 0.7464\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.6336 - acc: 0.7749\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.6062 - acc: 0.7867\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.5791 - acc: 0.7980\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.5235 - acc: 0.8094\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.5049 - acc: 0.8251\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.4970 - acc: 0.8256\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.4415 - acc: 0.8471\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.4462 - acc: 0.8427\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 25s 79ms/step - loss: 0.3934 - acc: 0.8590\n"
     ]
    }
   ],
   "source": [
    "stolen_clf1 = attack_CCC.extract(partial_x_train, thieved_classifier=stolen_clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_KN = KnockoffNets(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=20,\n",
    "                        nb_stolen=10000,\n",
    "                        sampling_strategy='adaptive')\n",
    "stolen_clf2 = attack_KN.extract(partial_x_train, partial_y_train, thieved_classifier=stolen_clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack_FEN = FunctionallyEquivalentExtraction(classifier=cloud_art_clf, num_neurons=100)\n",
    "# stolen_clf_FEN = attack_FEN.extract(partial_x_train, partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sanity check\n",
    "stolen_clf1._model.evaluate(partial_x_train, partial_y_train)\n",
    "\n",
    "stolen_clf2._model.evaluate(partial_x_train, partial_y_train)\n",
    "\n",
    "# stolen_clf_FEN._model.evaluate(partial_x_train, partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cloud_art_clf._model.evaluate(x_train_adv, y_train_adv)\n",
    "stolen_clf1._model.evaluate(x_train_adv, y_train_adv)\n",
    "stolen_clf2._model.evaluate(x_train_adv, y_train_adv)\n",
    "# stolen_clf_FEN._model.evaluate(x_train_adv, y_train_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_art_clf._model.evaluate(x_test_adv, y_test_adv)\n",
    "stolen_clf1._model.evaluate(x_test_adv, y_test_adv)\n",
    "stolen_clf2._model.evaluate(x_test_adv, y_test_adv)\n",
    "# stolen_clf_FEN._model.evaluate(x_test_adv, y_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Adversarial CIFAR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
