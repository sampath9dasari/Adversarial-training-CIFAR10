{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow_hub as thub\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from lib.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import InputLayer, Reshape\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks.extraction import CopycatCNN, FunctionallyEquivalentExtraction, KnockoffNets\n",
    "import art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample_by_class(data, labels, num_samples=100):\n",
    "    sample_data = []\n",
    "    sample_labels = []\n",
    "    unq_labels = list(range(labels.shape[1]))\n",
    "    for label in unq_labels:\n",
    "        idx = labels[:,label]==1\n",
    "        sample_set = data[idx][0:num_samples].copy()\n",
    "        label_set = labels[idx][0:num_samples].copy()\n",
    "        sample_data.append(sample_set)\n",
    "        sample_labels.append(label_set)\n",
    "    \n",
    "    sample_data = np.concatenate(sample_data)\n",
    "    sample_labels = np.concatenate(sample_labels)\n",
    "    print(sample_data.shape, sample_labels.shape)\n",
    "    return sample_data, sample_labels\n",
    "\n",
    "def subset_data(data, labels, fraction=5):\n",
    "    data_size = data.shape[0]\n",
    "    out_size = int(data_size*fraction/100)\n",
    "    idx = np.random.choice(data_size, out_size, replace=False)\n",
    "    out_data = data[idx].copy()\n",
    "    out_labels = labels[idx].copy()\n",
    "    \n",
    "    print(out_data.shape, out_labels.shape)\n",
    "    return out_data, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data\n",
    "cifar10_dir = 'lib/datasets/cifar-10-batches-py'\n",
    "x_train, y_train, x_test, y_test = load_cifar10(cifar10_dir)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_ganeval_model(enable_logits=True):\n",
    "    K.clear_session()\n",
    "    model_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n",
    "    ganeval_module = thub.Module(model_url)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(32,32,3)))\n",
    "    model.add(thub.KerasLayer(ganeval_module))\n",
    "    if enable_logits:\n",
    "        model.add(Activation('linear'))\n",
    "    else: \n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=1e-4),\n",
    "                  loss=CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 10)                7796426   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,796,426\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,796,426\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ge_cifar_clf = build_ganeval_model(enable_logits=True)\n",
    "ge_cifar_clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the retrieved hub model by evaluating on train data\n",
    "Should give us 100% or something close to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 0.0017 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001668029203079641, 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_cifar_clf.evaluate(testd, testl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a sample attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "attack_fgsm = FastGradientMethod(classifier=classifier, eps=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_test_adv = attack_fgsm.generate(testd.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ge_cifar_clf.evaluate(x_test_adv, testl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the substitute classifier for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_substitute_model(enable_logits=True):\n",
    "    model = tf.keras.Sequential( )\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32,32,3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    if enable_logits:\n",
    "        model.add(Activation(\"linear\"))\n",
    "    else:\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'] )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sub_model = build_substitute_model()\n",
    "sub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to execute Extraction attack and return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extraction_attack(ART_attack, x_train, y_train, fractions, epoch=30, verbose=0):\n",
    "    \n",
    "    data_size = x_train.shape[0]\n",
    "    epochs = epoch\n",
    "    \n",
    "    ### Train and Test sample data from each class to get final results\n",
    "    print(\"Extract 100 Training samples from each class:\")\n",
    "    x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "    print(\"Extract 100 Test samples from each class:\")\n",
    "    x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)\n",
    "    \n",
    "    ge_cifar_clf = build_ganeval_model()\n",
    "    cloud_art_clf = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "    \n",
    "    loss1, acc1 = cloud_art_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "    loss2, acc2 = cloud_art_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "    \n",
    "    clf_results = []\n",
    "    \n",
    "    for each_frac in fractions:\n",
    "        max_queries = int(data_size*each_frac/100)\n",
    "        print(\"Attacking the victim with %d percent of training data: %d queries...\"%(each_frac, max_queries))\n",
    "#         partial_x_train, partial_y_train = subset_data(x_train, y_train, fraction=each_frac)\n",
    "        \n",
    "        sub_clf = build_substitute_model()\n",
    "        stolen_clf = KerasClassifier(model=sub_clf, clip_values=(0, 1), use_logits=True)\n",
    "        \n",
    "        attack = ART_attack(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=epochs,\n",
    "                        nb_stolen=max_queries)\n",
    "        \n",
    "        stolen_clf = attack.extract(x_train, thieved_classifier=stolen_clf)\n",
    "\n",
    "        loss3, acc3 = stolen_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "        loss4, acc4 = stolen_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "        \n",
    "        clf_results.append((ART_attack.__name__, each_frac, max_queries, epochs,\n",
    "                            (round(loss1,4), acc1), (round(loss2,4), acc2), \n",
    "                            (round(loss3,4), acc3), (round(loss4,4), acc4)))\n",
    "        \n",
    "        results_df = pd.DataFrame(clf_results, columns=['Attack', 'Fraction of data', 'Max queries', \n",
    "                                                        'Epochs trained', 'Victim clf on Train data',\n",
    "                                                       'Victim clf on Test data', 'Stolen clf on Train data', \n",
    "                                                        'Stolen clf on Test data'])\n",
    "    return results_df\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Knockoff Nets attack with Random Sampling Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "KON_results_20e = extraction_attack(KnockoffNets, x_train, y_train, [5,10,20,30], epoch=20)\n",
    "KON_results_30e = extraction_attack(KnockoffNets, x_train, y_train, [5,10,20,30], epoch=30)\n",
    "KON_results_40e = extraction_attack(KnockoffNets, x_train, y_train, [5,10,20,30], epoch=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Copycat CNN attack with problem domain data with Stolen labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CCC_results_20e = extraction_attack(CopycatCNN, x_train, y_train, [5,10,20,30], epoch=20)\n",
    "CCC_results_30e = extraction_attack(CopycatCNN, x_train, y_train, [5,10,20,30], epoch=30)\n",
    "CCC_results_40e = extraction_attack(CopycatCNN, x_train, y_train, [5,10,20,30], epoch=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EA_results = pd.concat([KON_results_20e,KON_results_30e,KON_results_40e,\n",
    "                        CCC_results_20e,CCC_results_30e,CCC_results_40e])\n",
    "EA_results.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EA_results.to_csv(\"Extraction attacks results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copycat CNN attack NPD-SL + PD-SL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to execute Copycat CNN with Non-problem domain + Problem domain data with stolen labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def CCC_extraction_attack(npd_data, x_train, y_train, fractions, epoch=30, verbose=0):\n",
    "    \n",
    "    data_size = x_train.shape[0]\n",
    "    epochs = epoch\n",
    "    npd_size = npd_data.shape[0]\n",
    "    \n",
    "    ### Train and Test sample data from each class to get final results\n",
    "    print(\"Extract 100 Training samples from each class:\")\n",
    "    x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "    print(\"Extract 100 Test samples from each class:\")\n",
    "    x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)\n",
    "    \n",
    "    ge_cifar_clf = build_ganeval_model()\n",
    "    cloud_art_clf = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "    \n",
    "    loss1, acc1 = cloud_art_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "    loss2, acc2 = cloud_art_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "            \n",
    "    sub_clf = build_substitute_model()\n",
    "    stolen_clf = KerasClassifier(model=sub_clf, clip_values=(0, 1), use_logits=True)\n",
    "    \n",
    "    attack = CopycatCNN(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=epochs,\n",
    "                        nb_stolen=npd_size)\n",
    "    \n",
    "    stolen_clf = attack.extract(npd_data, thieved_classifier=stolen_clf)\n",
    "    \n",
    "    stolen_clf._model.save_weights(\"CCC_temp.h5\")\n",
    "    \n",
    "    clf_results = []\n",
    "    \n",
    "    for each_frac in fractions:\n",
    "\n",
    "        max_queries = int(data_size*each_frac/100)\n",
    "        print(\"Attacking the victim with %d percent of training data: %d queries...\"%(each_frac, max_queries))\n",
    "        \n",
    "        stolen_clf._model.load_weights(\"CCC_temp.h5\")\n",
    "        partial_x_train, _ = subset_data(x_train, y_train, fraction=each_frac)\n",
    "\n",
    "        stolen_clf = attack.extract(partial_x_train, thieved_classifier=stolen_clf)\n",
    "        \n",
    "        loss3, acc3 = stolen_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "        loss4, acc4 = stolen_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "        \n",
    "        clf_results.append((\"Copycat CNN\", npd_size, each_frac, max_queries, epochs, \n",
    "                            (round(loss1,4), acc1), \n",
    "                            (round(loss2,4), acc2), \n",
    "                            (round(loss3,4), acc3), \n",
    "                            (round(loss4,4), acc4)))\n",
    "        \n",
    "        results_df = pd.DataFrame(clf_results, columns=['Attack', \"NPD Queries\", 'Fraction of train data', \n",
    "                                                        'Train queries', \n",
    "                                                        'Epochs trained', 'Victim clf on Train data',\n",
    "                                                       'Victim clf on Test data', 'Stolen clf on Train data', \n",
    "                                                        'Stolen clf on Test data'])\n",
    "    return results_df\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Prepare CIFAR100 dataset for NPD purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "(cifar100_x, cifar100_y), _ = cifar100.load_data(label_mode='fine')\n",
    "print('cifar100 training data shape:', cifar100_x.shape)\n",
    "\n",
    "# Normalize pixel values\n",
    "cifar100_x = cifar100_x/255\n",
    "\n",
    "# Sample 20,000 data points randomly from the data\n",
    "idx = np.random.choice(cifar100_x.shape[0], 20000, replace=False)\n",
    "cifar100_x = cifar100_x[idx].copy()\n",
    "cifar100_y = cifar100_y[idx].copy()\n",
    "\n",
    "print('Final NPD size of cifar100 training data:', cifar100_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Copycat CNN attack with CIFAR100 as NPD and partial CIFAR10 as PD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CCC_results_30e = CCC_extraction_attack(cifar100_x, x_train, y_train, [5,10,20,30], epoch=30)\n",
    "CCC_results_40e = CCC_extraction_attack(cifar100_x, x_train, y_train, [5,10,20,30], epoch=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CCC_results = pd.concat([CCC_results_30e,CCC_results_40e])\n",
    "CCC_results.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CCC_results.to_csv(\"Extraction attack - Copycat CNN results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionally Equivalent Extraction attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking 100 samples from each class for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking a fraction of training data randomly to perform extraction attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partial_x_train, partial_y_train = subset_data(x_train, y_train, fraction=0.2)\n",
    "\n",
    "partial_x_train = partial_x_train.reshape(-1,32*32*3)\n",
    "\n",
    "### Tried even with standardizing the values around '0'\n",
    "x_mean = partial_x_train.mean()\n",
    "x_std = partial_x_train.std()\n",
    "# partial_x_train = (partial_x_train - x_mean)/x_std\n",
    "\n",
    "partial_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple two-layered Victim/Oracle model for CIFAR10 to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_eval_model = Sequential()\n",
    "fen_eval_model.add(Dense(1024, activation=\"relu\", input_shape=(32*32*3,)))\n",
    "fen_eval_model.add(Dense(10, activation=\"linear\"))\n",
    "\n",
    "fen_eval_model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_eval_model.fit(x_train.reshape(-1,32*32*3), y_train, batch_size=32, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_eval_model.evaluate(x_test.reshape(-1,32*32*3), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_eval_model.evaluate(partial_x_train, partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flat_art_clf = KerasClassifier(model=fen_eval_model, clip_values=(0, 1), use_logits=False)\n",
    "\n",
    "attack_FEN = FunctionallyEquivalentExtraction(classifier=flat_art_clf, num_neurons=1024)\n",
    "stolen_clf_FEN = attack_FEN.extract(partial_x_train, partial_y_train,\n",
    "                                    delta_0=0.05,\n",
    "                                    fraction_true=0.3,\n",
    "                                    rel_diff_slope=0.1,\n",
    "                                    rel_diff_value=0.1,\n",
    "                                    delta_init_value=0.1,\n",
    "                                    delta_value_max=2,\n",
    "                                    d2_min=0.04,\n",
    "                                    d_step=0.01,\n",
    "                                    delta_sign=0.2,\n",
    "                                    unit_vector_scale=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Trial 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A flattened input Ganeval-cifar10-convnet model to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_ganeval_model_flat():\n",
    "    K.clear_session()\n",
    "    model_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n",
    "    ganeval_module = thub.Module(model_url)\n",
    "    \n",
    "    model = Sequential()\n",
    "#     model.add(InputLayer(input_shape=(32*32*3,)))\n",
    "    model.add(Reshape((32,32,3),input_shape=(32*32*3,)))\n",
    "    model.add(thub.KerasLayer(ganeval_module))\n",
    "    model.add(Activation('relu'))\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=1e-4),\n",
    "                  loss=CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "keras_layer (KerasLayer)     (None, 10)                7796426   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,796,426\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,796,426\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ge_flat_clf = build_ganeval_model_flat()\n",
    "ge_flat_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_flat_clf.evaluate(partial_x_train, partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_art_clf = KerasClassifier(model=ge_flat_clf, clip_values=(0, 1), use_logits=False)\n",
    "\n",
    "attack_FEN = FunctionallyEquivalentExtraction(classifier=flat_art_clf, num_neurons=100)\n",
    "stolen_clf_FEN = attack_FEN.extract(partial_x_train, partial_y_train,\n",
    "                                    delta_0=0.05,\n",
    "                                    fraction_true=0.3,\n",
    "                                    rel_diff_slope=0.1,\n",
    "                                    rel_diff_value=0.1,\n",
    "                                    delta_init_value=0.1,\n",
    "                                    delta_value_max=2,\n",
    "                                    d2_min=0.04,\n",
    "                                    d_step=0.01,\n",
    "                                    delta_sign=0.2,\n",
    "                                    unit_vector_scale=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never got till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Sanity check\n",
    "stolen_clf_FEN._model.evaluate(partial_x_train, partial_y_train)\n",
    "\n",
    "### Evaluation\n",
    "stolen_clf_FEN._model.evaluate(x_train_adv, y_train_adv)\n",
    "stolen_clf_FEN._model.evaluate(x_test_adv, y_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Adversarial CIFAR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyCharm (Adversarial-training-CIFAR10)",
   "language": "python",
   "name": "pycharm-1463dd30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
