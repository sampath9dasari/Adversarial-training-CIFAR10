{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow_hub as thub\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from lib.data_utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import InputLayer, Reshape\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks.extraction import CopycatCNN, FunctionallyEquivalentExtraction, KnockoffNets\n",
    "import art"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_by_class(data, labels, num_samples=100):\n",
    "    sample_data = []\n",
    "    sample_labels = []\n",
    "    unq_labels = list(range(labels.shape[1]))\n",
    "    for label in unq_labels:\n",
    "        idx = labels[:,label]==1\n",
    "        sample_set = data[idx][0:num_samples].copy()\n",
    "        label_set = labels[idx][0:num_samples].copy()\n",
    "        sample_data.append(sample_set)\n",
    "        sample_labels.append(label_set)\n",
    "    \n",
    "    sample_data = np.concatenate(sample_data)\n",
    "    sample_labels = np.concatenate(sample_labels)\n",
    "    print(sample_data.shape, sample_labels.shape)\n",
    "    return sample_data, sample_labels\n",
    "\n",
    "def subset_data(data, labels, fraction=5):\n",
    "    data_size = data.shape[0]\n",
    "    out_size = int(data_size*fraction/100)\n",
    "    idx = np.random.choice(data_size, out_size, replace=False)\n",
    "    out_data = data[idx].copy()\n",
    "    out_labels = labels[idx].copy()\n",
    "    \n",
    "    print(out_data.shape, out_labels.shape)\n",
    "    return out_data, out_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data\n",
    "cifar10_dir = 'lib/datasets/cifar-10-batches-py'\n",
    "x_train, y_train, x_test, y_test = load_cifar10(cifar10_dir)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testd = x_train[0:1000].copy()\n",
    "testl = y_train[0:1000].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_ganeval_model(enable_logits=True):\n",
    "    K.clear_session()\n",
    "    model_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n",
    "    ganeval_module = thub.Module(model_url)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(32,32,3)))\n",
    "    model.add(thub.KerasLayer(ganeval_module))\n",
    "    if enable_logits:\n",
    "        model.add(Activation('linear'))\n",
    "    else: \n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=1e-4),\n",
    "                  loss=CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_ganeval_model_flat(enable_logits=True):\n",
    "    K.clear_session()\n",
    "    model_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n",
    "    ganeval_module = thub.Module(model_url)\n",
    "    \n",
    "    model = Sequential()\n",
    "#     model.add(InputLayer(input_shape=(32*32*3,)))\n",
    "    model.add(Reshape((32,32,1),input_shape=(32*32*1,)))\n",
    "    model.add(Conv2D(3, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(thub.KerasLayer(ganeval_module))\n",
    "    if enable_logits:\n",
    "        model.add(Activation('linear'))\n",
    "    else: \n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=1e-4),\n",
    "                  loss=CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ge_flat_clf = build_ganeval_model_flat()\n",
    "ge_flat_clf.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ge_cifar_clf = build_ganeval_model(enable_logits=True)\n",
    "ge_cifar_clf.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing the retrieved hub model by evaluating on train data\n",
    "Should give us 100% or something close to that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ge_cifar_clf.evaluate(testd, testl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing a sample attack"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "attack_fgsm = FastGradientMethod(classifier=classifier, eps=0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test_adv = attack_fgsm.generate(testd.copy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ge_cifar_clf.evaluate(x_test_adv, testl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the substitute classifier for our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def build_substitute_model(enable_logits=True):\n",
    "#     model = tf.keras.Sequential( )\n",
    "#     model.add( Conv2D( 32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32,32,3) ) )\n",
    "#     model.add( Conv2D( 64, (3, 3), padding='same', activation='relu' ) )\n",
    "#     model.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
    "#     model.add( Flatten( ) )\n",
    "#     model.add( Dense( 128, activation='relu' ) )\n",
    "#     if enable_logits:\n",
    "#         model.add( Dense(10, activation='linear' ) )\n",
    "#     else:\n",
    "#         model.add( Dense(10, activation='softmax' ) )\n",
    "        \n",
    "#     model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=enable_logits),\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['accuracy'] )\n",
    "    \n",
    "\n",
    "    \n",
    "#     return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def build_substitute_model(enable_logits=True):\n",
    "    model = tf.keras.Sequential( )\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32,32,3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    if enable_logits:\n",
    "        model.add(Activation(\"linear\"))\n",
    "    else:\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "    model.compile(loss=CategoricalCrossentropy(from_logits=enable_logits),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'] )\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extraction_attack(ART_attack, x_train, y_train, fractions, epoch=30, verbose=0):\n",
    "    \n",
    "    data_size = x_train.shape[0]\n",
    "    epochs = epoch\n",
    "    \n",
    "    ### Train and Test sample data from each class to get final results\n",
    "    print(\"Extract 100 Training samples from each class:\")\n",
    "    x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "    print(\"Extract 100 Test samples from each class:\")\n",
    "    x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)\n",
    "    \n",
    "    ge_cifar_clf = build_ganeval_model()\n",
    "    cloud_art_clf = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "    \n",
    "    loss1, acc1 = cloud_art_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "    loss2, acc2 = cloud_art_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "    \n",
    "    clf_results = []\n",
    "    \n",
    "    for each_frac in fractions:\n",
    "        max_queries = int(data_size*each_frac/100)\n",
    "        print(\"Attacking the victim with %d percent of training data: %d queries...\"%(each_frac, max_queries))\n",
    "#         partial_x_train, partial_y_train = subset_data(x_train, y_train, fraction=each_frac)\n",
    "        \n",
    "        sub_clf = build_substitute_model()\n",
    "        stolen_clf = KerasClassifier(model=sub_clf, clip_values=(0, 1), use_logits=True)\n",
    "        \n",
    "        attack = ART_attack(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=epochs,\n",
    "                        nb_stolen=max_queries)\n",
    "        \n",
    "        stolen_clf = attack.extract(x_train, thieved_classifier=stolen_clf)\n",
    "\n",
    "        loss3, acc3 = stolen_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "        loss4, acc4 = stolen_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "        \n",
    "        clf_results.append((ART_attack.__name__, each_frac, max_queries, epochs, (round(loss1,4), acc1), (round(loss2,4), acc2), \n",
    "                            (round(loss3,4), acc3), (round(loss4,4), acc4)))\n",
    "        \n",
    "        results_df = pd.DataFrame(clf_results, columns=['Attack', 'Fraction of data', 'Max queries', 'Epochs trained', 'Victim clf on Train data',\n",
    "                                                       'Victim clf on Test data', 'Stolen clf on Train data', \n",
    "                                                        'Stolen clf on Test data'])\n",
    "    return results_df\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KON_results_20e = extraction_attack(KnockoffNets, x_train, y_train, [5,10,20,30], epoch=20)\n",
    "KON_results_30e = extraction_attack(KnockoffNets, x_train, y_train, [5,10,20,30], epoch=30)\n",
    "KON_results_40e = extraction_attack(KnockoffNets, x_train, y_train, [5,10,20,30], epoch=40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KON_results_20e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KON_results_30e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KON_results_40e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_20e = extraction_attack(CopycatCNN, x_train, y_train, [5,10,20,30], epoch=20)\n",
    "CCC_results_30e = extraction_attack(CopycatCNN, x_train, y_train, [5,10,20,30], epoch=30)\n",
    "CCC_results_40e = extraction_attack(CopycatCNN, x_train, y_train, [5,10,20,30], epoch=40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_20e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_30e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_40e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EA_results = pd.concat([KON_results_20e,KON_results_30e,KON_results_40e,CCC_results_20e,CCC_results_30e,CCC_results_40e])\n",
    "EA_results.head(24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EA_results.to_csv(\"Extraction attacks results.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "partial_x_train, partial_y_train = subset_data(x_train, y_train, fraction=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Copycat CNN attack NPD-SL + PD-SL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def CCC_extraction_attack(npd_data, x_train, y_train, fractions, epoch=30, verbose=0):\n",
    "    \n",
    "    data_size = x_train.shape[0]\n",
    "    epochs = epoch\n",
    "    npd_size = npd_data.shape[0]\n",
    "    \n",
    "    ### Train and Test sample data from each class to get final results\n",
    "    print(\"Extract 100 Training samples from each class:\")\n",
    "    x_train_adv, y_train_adv = sample_by_class(x_train, y_train, num_samples=100)\n",
    "    print(\"Extract 100 Test samples from each class:\")\n",
    "    x_test_adv, y_test_adv = sample_by_class(x_test, y_test, num_samples=100)\n",
    "    \n",
    "    ge_cifar_clf = build_ganeval_model()\n",
    "    cloud_art_clf = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "    \n",
    "    loss1, acc1 = cloud_art_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "    loss2, acc2 = cloud_art_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "            \n",
    "    sub_clf = build_substitute_model()\n",
    "    stolen_clf = KerasClassifier(model=sub_clf, clip_values=(0, 1), use_logits=True)\n",
    "    \n",
    "    attack = CopycatCNN(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=epochs,\n",
    "                        nb_stolen=npd_size)\n",
    "    \n",
    "    stolen_clf = attack.extract(npd_data, thieved_classifier=stolen_clf)\n",
    "    \n",
    "    stolen_clf._model.save_weights(\"CCC_temp.h5\")\n",
    "    \n",
    "    clf_results = []\n",
    "    \n",
    "    for each_frac in fractions:\n",
    "\n",
    "        max_queries = int(data_size*each_frac/100)\n",
    "        print(\"Attacking the victim with %d percent of training data: %d queries...\"%(each_frac, max_queries))\n",
    "        \n",
    "        stolen_clf._model.load_weights(\"CCC_temp.h5\")\n",
    "        partial_x_train, _ = subset_data(x_train, y_train, fraction=each_frac)\n",
    "\n",
    "        stolen_clf = attack.extract(partial_x_train, thieved_classifier=stolen_clf)\n",
    "        \n",
    "        loss3, acc3 = stolen_clf._model.evaluate(x_train_adv, y_train_adv, verbose=verbose)\n",
    "        loss4, acc4 = stolen_clf._model.evaluate(x_test_adv, y_test_adv, verbose=verbose)\n",
    "        \n",
    "        clf_results.append((\"Copycat CNN\", npd_size, each_frac, max_queries, epochs, \n",
    "                            (round(loss1,4), acc1), \n",
    "                            (round(loss2,4), acc2), \n",
    "                            (round(loss3,4), acc3), \n",
    "                            (round(loss4,4), acc4)))\n",
    "        \n",
    "        results_df = pd.DataFrame(clf_results, columns=['Attack', \"NPD Queries\", 'Fraction of train data', \n",
    "                                                        'Train queries', \n",
    "                                                        'Epochs trained', 'Victim clf on Train data',\n",
    "                                                       'Victim clf on Test data', 'Stolen clf on Train data', \n",
    "                                                        'Stolen clf on Test data'])\n",
    "    return results_df\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(cifar100_x, cifar100_y), _ = cifar100.load_data(label_mode='fine')\n",
    "print('cifar100 training data shape:', cifar100_x.shape)\n",
    "\n",
    "# Normalize pixel values\n",
    "cifar100_x = cifar100_x/255\n",
    "\n",
    "# Sample 20,000 data points randomly from the data\n",
    "idx = np.random.choice(cifar100_x.shape[0], 20000, replace=False)\n",
    "cifar100_x = cifar100_x[idx].copy()\n",
    "cifar100_y = cifar100_y[idx].copy()\n",
    "\n",
    "print('Final NPD size of cifar100 training data:', cifar100_x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_30e = CCC_extraction_attack(cifar100_x, x_train, y_train, [5,10,20,30], epoch=30)\n",
    "CCC_results_40e = CCC_extraction_attack(cifar100_x, x_train, y_train, [5,10,20,30], epoch=40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_30e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results_40e.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results = pd.concat([CCC_results_30e,CCC_results_40e])\n",
    "CCC_results.head(24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CCC_results.to_csv(\"Extraction attack - Copycat CNN results.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/adver_tf1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ge_cifar_clf = build_ganeval_model()\n",
    "sub_clf1 = build_substitute_model()\n",
    "# sub_clf2 = build_substitute_model()\n",
    "sub_clf1.summary()\n",
    "# sub_clf2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud_art_clf = KerasClassifier(model=ge_cifar_clf, clip_values=(0, 1), use_logits=True)\n",
    "stolen_clf1 = KerasClassifier(model=sub_clf1, clip_values=(0, 1), use_logits=True)\n",
    "stolen_clf2 = KerasClassifier(model=sub_clf2, clip_values=(0, 1), use_logits=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attack_CCC = CopycatCNN(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=20,\n",
    "                        nb_stolen=20000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stolen_clf1 = attack_CCC.extract(cifar100_x, thieved_classifier=stolen_clf1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_clf1.save_weights(\"CCC_temp.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stolen_clf1 = attack_CCC.extract(partial_x_train, thieved_classifier=stolen_clf1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stolen_clf1._model.save_weights(\"CCC_temp1.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stolen_clf1 = attack_CCC.extract(partial_x_train, thieved_classifier=stolen_clf1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stolen_clf1._model.evaluate(partial_x_train, partial_y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stolen_clf1._model.evaluate(partial_x_train, partial_y_train)\n",
    "cloud_art_clf._model.evaluate(x_train_adv, y_train_adv)\n",
    "stolen_clf1._model.evaluate(x_train_adv, y_train_adv)\n",
    "cloud_art_clf._model.evaluate(x_test_adv, y_test_adv)\n",
    "stolen_clf1._model.evaluate(x_test_adv, y_test_adv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "attack_KN = KnockoffNets(classifier=cloud_art_clf, \n",
    "                        batch_size_fit=32, \n",
    "                        batch_size_query=32,\n",
    "                        nb_epochs=2,\n",
    "                        nb_stolen=2000,\n",
    "                        sampling_strategy='random')\n",
    "stolen_clf2 = attack_KN.extract(partial_x_train, partial_y_train, thieved_classifier=stolen_clf2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ge_flat_clf = build_ganeval_model_flat()\n",
    "ge_flat_clf.summary()\n",
    "\n",
    "partial_x_train, partial_y_train = subset_data(x_train, y_train, fraction=0.2)\n",
    "partial_x_train = partial_x_train[:,:,:,0]\n",
    "\n",
    "x_mean = partial_x_train.mean()\n",
    "x_std = partial_x_train.std()\n",
    "\n",
    "partial_x_train = (partial_x_train.reshape(-1,32*32*1) - x_mean)/x_std\n",
    "partial_x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ge_flat_clf.evaluate(partial_x_train, partial_y_train)\n",
    "\n",
    "flat_art_clf = KerasClassifier(model=ge_flat_clf, clip_values=(0, 1), use_logits=True)\n",
    "\n",
    "attack_FEN = FunctionallyEquivalentExtraction(classifier=flat_art_clf, num_neurons=10)\n",
    "stolen_clf_FEN = attack_FEN.extract(partial_x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Sanity check\n",
    "stolen_clf1._model.evaluate(partial_x_train, partial_y_train)\n",
    "\n",
    "stolen_clf2._model.evaluate(partial_x_train, partial_y_train)\n",
    "\n",
    "# stolen_clf_FEN._model.evaluate(partial_x_train, partial_y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud_art_clf._model.evaluate(x_train_adv, y_train_adv)\n",
    "stolen_clf1._model.evaluate(x_train_adv, y_train_adv)\n",
    "stolen_clf2._model.evaluate(x_train_adv, y_train_adv)\n",
    "# stolen_clf_FEN._model.evaluate(x_train_adv, y_train_adv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud_art_clf._model.evaluate(x_test_adv, y_test_adv)\n",
    "stolen_clf1._model.evaluate(x_test_adv, y_test_adv)\n",
    "stolen_clf2._model.evaluate(x_test_adv, y_test_adv)\n",
    "# stolen_clf_FEN._model.evaluate(x_test_adv, y_test_adv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Adversarial CIFAR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-1463dd30",
   "language": "python",
   "display_name": "PyCharm (Adversarial-training-CIFAR10)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}